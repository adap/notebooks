{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# Using Flower on AWS with Terraform\n",
        "\n",
        "Welcome to the federated learning tutorial!\n",
        "\n",
        "This notebook will show how to build a federated learning system and deploy it on AWS. At the end of this tutorial three AWS VMs are running while one will be the server and two others will represent clients.\n",
        "\n",
        "[Terraform](https://www.terraform.io/) will be used to provision the infrastructure. For those whom never heard of Terraform this quote from its website will give an idea:\n",
        "\n",
        ">Terraform is an open-source infrastructure as code software tool that provides a consistent CLI workflow to manage hundreds of cloud services. Terraform codifies cloud APIs into declarative configuration files.\n",
        "\n",
        "Putting it simply Terraform will enable to create infrastructure in a repeatable and usually predictable way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Infrastructure\n",
        "\n",
        "Before beginning with any actual code, make sure you have access to an AWS account. You will need a AWS_ACCESS_KEY as well as the corresponding AWS_SECRET_ACCESS_KEY. Here you can find a guide how to create and get those: [How do I create an AWS access key?](https://aws.amazon.com/de/premiumsupport/knowledge-center/create-access-key)\n",
        "\n",
        "Make sure to NOT share them with anyone or leak them accidentally as others could gain full control over your account using these secrets. When you are ready you can enter your credentials into the next section which will enable tools such as Terraform to access your AWS account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKvYZefjaIF3"
      },
      "outputs": [],
      "source": [
        "# Set environment variables with `%env` magic command specific to Jupyter\n",
        "# Outside of Jupyter you would replace `%env` with `export`\n",
        "%env AWS_ACCESS_KEY_ID=REPLACE_ME\n",
        "%env AWS_SECRET_ACCESS_KEY=REPLACE_ME\n",
        "%env AWS_DEFAULT_REGION=eu-central-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "Running this notebook requires Terraform which is going to be installed using some statements form the official installation [guide](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/aws-get-started). This will work on Google Colab as well as on any Debian based system as apt is used to install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_kNaDi1aIF6"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "export DEBIAN_FRONTEND=noninteractive\n",
        "sudo apt-get update && sudo apt-get install -y gnupg software-properties-common curl\n",
        "curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -\n",
        "sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\"\n",
        "sudo apt-get update && sudo apt-get install terraform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvVOQe0WaIF7"
      },
      "source": [
        "### Provision EC2 instances\n",
        "\n",
        "With Terraform installed, you are ready to create the infrastructure nessecary to run a Flower server and two clients.\n",
        "\n",
        "In this tutorial, you will provision an EC2 instance on Amazon Web Services (AWS). EC2 instances are virtual machines running on AWS. They can be started using a variety of machine images. The image used will be based on Ubuntu 20.04.\n",
        "\n",
        "#### Configuration\n",
        "\n",
        "For the purpose of grouping all configuration files a directory called `infrastructure` is going to be created. All configuration files will be written into that directory. Additionally a SSH key will be created which is later going to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "4nMnioDTaIF8"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create directory infrastructure and use -p so this command becomes idempotent\n",
        "mkdir -p ./infrastructure\n",
        "\n",
        "# Create ssh key to be used later to connect ot the machines\n",
        "cd infrastructure\n",
        "\n",
        "# Create SSH key with name flower_notebook_rsa if it does not exist\n",
        "if [[ ! -f \"./flower_notebook_rsa\" ]]; then\n",
        "    ssh-keygen -b 2048 -t rsa -N '' -f ./flower_notebook_rsa\n",
        "fi\n",
        "\n",
        "# You public key. You will need this later.\n",
        "echo \"You public key (copy this)\"\n",
        "cat flower_notebook_rsa.pub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbq1VCoLaIF9"
      },
      "source": [
        "When provisioning the machines it is desireable that they are automatically configured on startup and be ready to run Flower code. Cloud-init is a standard configuration support tool available on most Linux distributions and all major cloud providers. It allows you to pass a shell script to the command which starts a cloud instance. That script can be used to install or configure the machine.\n",
        "\n",
        "In the next step a shell script will be written to the `infrastructure` directory. It will be pass used in the Terraform configuration so it is run when the machine is provisioned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "6Wtn8EZeaIF9"
      },
      "outputs": [],
      "source": [
        "%%writefile ./infrastructure/user_data.sh\n",
        "#!/bin/bash\n",
        "set -e\n",
        "\n",
        "# Install dependencies\n",
        "sudo apt-get update\n",
        "sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release openssh-client python3 python3-pip\n",
        "\n",
        "# Install Flower\n",
        "python3 -m pip install flwr==0.18.0 torch==1.11.0 torchvision==0.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZa-DNbNaIF-"
      },
      "source": [
        "Now the Terraform `main.tf` file which will contain the primary entrypoint to our Terraform configuration will be written. It is not nessecary to understand the intricacies of this but for all who are interested it is recommend going through the offical Terraform [\"Get Started - AWS\"](https://learn.hashicorp.com/collections/terraform/aws-get-started) tutorial for AWS. Similarly there are also tutorials for cloud providers such as Azure, GCP and others.\n",
        "\n",
        "The previously created public key needs to be inserted here into the Terraform configuration. Scroll up and copy the public key. Replace the string \"REPLACE_ME\" in line 30 before executing the next segment and writing the configuration to disk.\n",
        "\n",
        "When reading the Terraform configuration it is worthwhile to have a deeper look at the security group configuration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./infrastructure/main.tf\n",
        "\n",
        "# Configure Terraform\n",
        "terraform {\n",
        "  required_providers {\n",
        "    aws = {\n",
        "      source  = \"hashicorp/aws\"\n",
        "      version = \"~> 3.27\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  required_version = \">= 0.14.9\"\n",
        "}\n",
        "\n",
        "# Configure AWS and the default region for all AWS resources\n",
        "provider \"aws\" {\n",
        "  profile = \"default\"\n",
        "  region  = \"eu-central-1\"\n",
        "}\n",
        "\n",
        "# This is going to be used so in a workshop the resources\n",
        "# created by the participants don't colide.\n",
        "resource \"random_pet\" \"name\" {}\n",
        "\n",
        "# Login in into the virtual machines requires a public SSH key to\n",
        "# be registered on the instance. Replace MY_PUBLIC_KEY down below\n",
        "# with your public SSH key.\n",
        "resource \"aws_key_pair\" \"default\" {\n",
        "  key_name   = \"flower-${random_pet.name.id}\"\n",
        "  public_key = \"REPLACE_ME\"\n",
        "}\n",
        "\n",
        "# Add one instance for the Flower server. We are using a m5a instance type\n",
        "# as the m instances are not limited by CPU credits. This is quite important\n",
        "# as the machines will utilize most of their resources. The m5a has 2 vCPU\n",
        "# and 8 GiB RAM. \n",
        "resource \"aws_instance\" \"flower_server\" {\n",
        "  # Use a data reference for cross-region compatibility\n",
        "  ami           = data.aws_ami.ubuntu.id\n",
        "  instance_type = \"m5a.large\"\n",
        "  key_name      = aws_key_pair.default.key_name\n",
        "\n",
        "  root_block_device {\n",
        "    # Size of disk in GiB\n",
        "    volume_size = \"30\"\n",
        "  }\n",
        "\n",
        "  user_data     = \"${file(\"user_data.sh\")}\"\n",
        "\n",
        "  vpc_security_group_ids = [\n",
        "    aws_security_group.flower.id\n",
        "  ]\n",
        "\n",
        "  tags = {\n",
        "    Name = \"FlowerServer\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Additionally we are going to start Flower instances\n",
        "resource \"aws_instance\" \"flower_clients\" {\n",
        "  # Use a data reference for cross-region compatibility\n",
        "  ami           = data.aws_ami.ubuntu.id\n",
        "  instance_type = \"m5a.large\"\n",
        "  key_name      = aws_key_pair.default.key_name\n",
        "  count         = 2\n",
        "\n",
        "  user_data     = \"${file(\"user_data.sh\")}\"\n",
        "\n",
        "  root_block_device {\n",
        "    # Size of disk in GiB\n",
        "    volume_size = \"30\"\n",
        "  }\n",
        "\n",
        "  vpc_security_group_ids = [\n",
        "    aws_security_group.flower.id\n",
        "  ]\n",
        "\n",
        "  tags = {\n",
        "    Name = \"FlowerClient\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Define a data element to make sure we get the right AWS AMI\n",
        "# independent of the region in which we start the EC2 instance.\n",
        "# The same AMI image might have different ID's in different \n",
        "# AWS regions.\n",
        "data \"aws_ami\" \"ubuntu\" {\n",
        "  most_recent = true\n",
        "\n",
        "  filter {\n",
        "    name   = \"name\"\n",
        "    values = [\"*ubuntu-focal-20.04-amd64-server-20211129\"]\n",
        "  }\n",
        "\n",
        "  filter {\n",
        "    name   = \"virtualization-type\"\n",
        "    values = [\"hvm\"]\n",
        "  }\n",
        "  # AWS owner id of Canonical\n",
        "  # Find out with:\n",
        "  # aws ec2 describe-images \\\n",
        "  # --filters \"Name=name,Values=*ubuntu-focal-20.04-amd64-server-20211129\"\n",
        "  owners = [\"099720109477\"]\n",
        "}\n",
        "\n",
        "resource \"aws_default_vpc\" \"default\" {\n",
        "  tags = {\n",
        "    Name = \"Default VPC\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# IMPORTANT\n",
        "# The security groups will configure which ports are externally reachable\n",
        "resource \"aws_security_group\" \"flower\" {\n",
        "  name        = \"flower-${random_pet.name.id}\"\n",
        "  description = \"All ports required for a Flower server\"\n",
        "  vpc_id      = aws_default_vpc.default.id\n",
        "\n",
        "  # In-comming traffic\n",
        "  # Allow port 22 so developers can connect to the server\n",
        "  # Allow port 8080 so Flower clients can connect to the Flower server\n",
        "  ingress = [\n",
        "    {\n",
        "      description      = \"SSH\"\n",
        "      from_port        = 22\n",
        "      to_port          = 22\n",
        "      protocol         = \"tcp\"\n",
        "      cidr_blocks      = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "      security_groups = null\n",
        "      prefix_list_ids  = null\n",
        "      self = null\n",
        "    },\n",
        "    {\n",
        "      description      = \"HTTP\"\n",
        "      from_port        = 8080\n",
        "      to_port          = 8080\n",
        "      protocol         = \"tcp\"\n",
        "      cidr_blocks      = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "      security_groups = null\n",
        "      prefix_list_ids  = null\n",
        "      self = null\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  # Out-going traffic\n",
        "  # Allow all ports when a connection is made from inside the server\n",
        "  # to the outside world\n",
        "  egress = [\n",
        "    {\n",
        "      description      = \"Any\"\n",
        "      from_port        = 0\n",
        "      to_port          = 0\n",
        "      protocol         = \"-1\"\n",
        "      cidr_blocks      = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "      security_groups = null\n",
        "      prefix_list_ids  = null\n",
        "      self = null\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  tags = {\n",
        "    Name = \"flower\"\n",
        "  }\n",
        "}\n",
        "\n",
        "output \"your_pet\" {\n",
        "    description = \"Your pets name\"\n",
        "    value       = \"${random_pet.name.id}\"\n",
        "}\n",
        "\n",
        "output \"server_ip\" {\n",
        "  description = \"Public IP address of server\"\n",
        "  value       = aws_instance.flower_server.public_ip\n",
        "}\n",
        "\n",
        "output \"client_1_ip\" {\n",
        "  description = \"Public IP address of clients\"\n",
        "  value       = aws_instance.flower_clients[0].public_ip\n",
        "}\n",
        "\n",
        "output \"client_2_ip\" {\n",
        "  description = \"Public IP address of clients\"\n",
        "  value       = aws_instance.flower_clients[1].public_ip\n",
        "}"
      ],
      "metadata": {
        "id": "D7HfPug4bNqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek8j39t2aIGB"
      },
      "source": [
        "#### Initialize Terraform\n",
        "\n",
        "Now its time to initialize Terraform in the infrastructure directory. As long as we don't have any errors in our Terraform files this should just work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OkieJCSaIGC"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jANI7QaaIGC"
      },
      "source": [
        "#### Create Infrastructure - plan & apply Terraform\n",
        "\n",
        "Now after Terraform is successfully initialized plan and apply the Terraform configuration. By doing so Terraform is going to create infrastructure in the AWS account. As a first step running `terraform plan` will show what Terraform would do if applied. Running `terraform apply -auto-approve` will do the plan step and immidiatly apply those. In a setting where these commands are run in a native terminal one can directly run `terraform apply` as Terraform will than (without the `-auto-approve` option present) ask the user if the proposed changes should be applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbJYn9pLaIGD"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform plan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of `terraform plan` shows what `terraform apply` will do. In a production workflow the output of the `plan` command would be written to disk and than reviewed. Here this is not done to keep it simple."
      ],
      "metadata": {
        "id": "kLBTrzsVby-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVPhfM_gaIGD"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform apply -auto-approve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btHW3bLnaIGE"
      },
      "source": [
        "As a note while Terraform will return its output earlier the execution of the cloud-init scripts start as soon as the machines are running. The IPs of these machines will later on be used upload or execute code on those. Copy those into the next code segment so it becomes easier later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQsITUHxaIGL"
      },
      "outputs": [],
      "source": [
        "# Replace the \"REPLACE_ME\" with the correct IP\n",
        "%env CLIENT_1_IP=REPLACE_ME\n",
        "%env CLIENT_2_IP=REPLACE_ME\n",
        "%env SERVER_IP=REPLACE_ME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Cgs7S3aIGL"
      },
      "source": [
        "#### Clean-up\n",
        "\n",
        "Now after the infrastructure is deployed and running it is also important to understand how to stop it. As long as its running it will incure cost which makes it quite important to remember to cleanup after our experiments are done. Ideally you should configure as much of the infrastructure in a way that its automatically cleaned up. The best way to remove infrastructure created with Terraform is to use the `terraform destroy` commmand. Terraform is stateful and the state in our case will be in `./infrastructure/.terraform`. Using the state Terraform will only destroy resource it created and not remove anything else. __Don't run this now!__ but rather come back here and run it when you stop working on this notebook and want to cleanup the infrastructure you have created. If you would like to test how it works you can naturally execute this code block now but you will have to provision the infrastructure once more by running the `terraform apply` code block. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2A-6yMCaIGM"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform destroy -auto-approve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYOjE3mJaIGM"
      },
      "source": [
        "## The experiment\n",
        "\n",
        "Three instances are now available but no Flower code is yet deployed. Application deployment can be quite complex and depending on various requirements. This tutorial will keep it simple so the concept is understood. The artifacts will be a `server.py` and `client.py` file which is uploaded to the respective machine. More advanced setups might use Docker containers which are pushed to a registry and than downloaded and started on the respective machines. Alternatively tools such as ArgoCD on a Kubernetes Cluster could be used. These more advanced setups can unfortunatly not be in the scope of this tutorial.\n",
        "\n",
        "The steps which will be taken in the next section will be:\n",
        "\n",
        "1. Write server.py and client.py to disk\n",
        "2. Upload files to respective machines\n",
        "3. Execute scripts in screen sessions\n",
        "4. Read logfiles to check progress\n",
        "\n",
        ">Note: The default Flower strategy `FedAvg` waits by default for two clients before starting a round of federation.\n",
        "\n",
        "### Preparation\n",
        "\n",
        "For the preparation we are going to create a directory called app where we will store all the files which we are going to upload to \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9lv_bCnaIGN"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create directory app and use -p so this command becomes idempotent\n",
        "mkdir -p ./app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZuWFNmQaIGN"
      },
      "source": [
        "### Server\n",
        "\n",
        "The first thing needed is a server. The default Flower server is extremly simple and will use FedAvg by default. For this showcase we will use just that and allow the user to customize the code after we have shown that everything works.\n",
        "\n",
        "As an important side not the `server_address=0.0.0.0:8080` in the next code segment technical instructs the server to listen on hosts for port `8080` and accept all connections made to it. If the `0.0.0.0` would be replaced with a certain IP or hostname it would only listen for requests made to that specific hostname. Therefore we are not going to change it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN1ZDoQIaIGO"
      },
      "outputs": [],
      "source": [
        "%%writefile ./app/server.py\n",
        "# Flower Server\n",
        "import flwr as fl\n",
        "\n",
        "# Start Flower server\n",
        "fl.server.start_server(\n",
        "  server_address=\"0.0.0.0:8080\",\n",
        "  config={\"num_rounds\": 3},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW0KWpjMaIGO"
      },
      "source": [
        "### Client\n",
        "\n",
        "Additionally the client script needs to be written and stored to disk. The client naturally needs to know the IP of the server. For this purpose scroll upwards and lookup in the Terraform output the server IP address and adjust the next code segment so that the correct IP address is inserted.\n",
        "\n",
        "_Hint: Look at the last line._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-YH_sM_aIGP"
      },
      "outputs": [],
      "source": [
        "%%writefile ./app/client.py\n",
        "# Flower Client\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# #############################################################################\n",
        "# Regular PyTorch pipeline: nn.Module, train, test, and DataLoader\n",
        "# #############################################################################\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net(nn.Module):\n",
        "  \"\"\"Model (simple CNN adapted from 'PyTorch: A 60 Minute Blitz')\"\"\"\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return self.fc3(x)\n",
        "\n",
        "def train(net, trainloader, epochs):\n",
        "  \"\"\"Train the model on the training set.\"\"\"\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "  for _ in range(epochs):\n",
        "    for images, labels in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      criterion(net(images.to(DEVICE)), labels.to(DEVICE)).backward()\n",
        "      optimizer.step()\n",
        "\n",
        "def test(net, testloader):\n",
        "  \"\"\"Validate the model on the test set.\"\"\"\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  correct, total, loss = 0, 0, 0.0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "      outputs = net(images.to(DEVICE))\n",
        "      loss += criterion(outputs, labels.to(DEVICE)).item()\n",
        "      total += labels.size(0)\n",
        "      correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  return loss / len(testloader.dataset), correct / total\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"Load CIFAR-10 (training and test set).\"\"\"\n",
        "  trf = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  trainset = CIFAR10(\"./data\", train=True, download=True, transform=trf)\n",
        "  testset = CIFAR10(\"./data\", train=False, download=True, transform=trf)\n",
        "  return DataLoader(trainset, batch_size=32, shuffle=True), DataLoader(testset)\n",
        "\n",
        "# #############################################################################\n",
        "# Federating the pipeline with Flower\n",
        "# #############################################################################\n",
        "\n",
        "# Load model and data (simple CNN, CIFAR-10)\n",
        "net = Net().to(DEVICE)\n",
        "trainloader, testloader = load_data()\n",
        "\n",
        "# Define Flower client\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "  def get_parameters(self):\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "  def set_parameters(self, parameters):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "  def fit(self, parameters, config):\n",
        "    self.set_parameters(parameters)\n",
        "    train(net, trainloader, epochs=1)\n",
        "    return self.get_parameters(), len(trainloader.dataset), {}\n",
        "\n",
        "  def evaluate(self, parameters, config):\n",
        "    self.set_parameters(parameters)\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    return float(loss), len(testloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "# Start Flower client\n",
        "# REPLACE_THIS_WITH_THE_SERVER_IP\n",
        "fl.client.start_numpy_client(\"REPLACE_THIS_WITH_THE_SERVER_IP:8080\", client=FlowerClient())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgLFoUmaIGQ"
      },
      "source": [
        "### Deployment\n",
        "\n",
        "After we have defined our `server.py` and `client.py` we have to upload those to the respective machines. Afterwards we are going to first start the server and following that the clients. For uploading the files we are going to use [scp](https://linux.die.net/man/1/scp) which can be find on most UNIX systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwwG9KHpaIGQ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Use `set -ex` to see the actual command with $SERVER_IP resolved\n",
        "# which will be executed and stop if any of the commands fail\n",
        "set -ex\n",
        "\n",
        "function upload {\n",
        "    scp -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" $@\n",
        "}\n",
        "\n",
        "# Upload code\n",
        "upload ./app/client.py ubuntu@$CLIENT_1_IP:/home/ubuntu/\n",
        "upload ./app/client.py ubuntu@$CLIENT_2_IP:/home/ubuntu/\n",
        "upload ./app/server.py ubuntu@$SERVER_IP:/home/ubuntu/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djl6c8ePaIGR"
      },
      "source": [
        "Next starting the server (wait a few seconds afterwards until the start is finished)\n",
        "\n",
        ">Using screen here so that the command continues to run when the ssh connection closes. When connecting to the instance via SSH one can easily connect to the screen session by using `screen -r`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR8es7goaIGR"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" ubuntu@$SERVER_IP \"screen -d -L -m python3 server.py && sleep 5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CrmfF3KaIGR"
      },
      "source": [
        "and the clients.\n",
        "\n",
        "Client 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH9MwCBdaIGS"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" ubuntu@$CLIENT_1_IP \"screen -d -L -m python3 client.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY91mx-2aIGT"
      },
      "source": [
        "Client 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgu6buGVaIGT"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" ubuntu@$CLIENT_2_IP \"screen -d -L -m python3 client.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MmAPTO-aIGT"
      },
      "source": [
        "### Logs\n",
        "\n",
        "As soon as the server runs it will be interesting to see the server logs. SSH will be used to run `cat` on the screenlog file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSeJ0pIuaIGT"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" ubuntu@$SERVER_IP \"cat screenlog.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuFu4LIIaIGT"
      },
      "source": [
        "Client 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCg_QAyJaIGU"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" ubuntu@$CLIENT_1_IP \"cat screenlog.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbyvtIwtaIGU"
      },
      "source": [
        "Client 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOXYAmxBaIGU"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" ubuntu@$CLIENT_2_IP \"cat screenlog.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4N3QpzJaIGV"
      },
      "source": [
        "## Clean-up\n",
        "\n",
        "As already mentioned previously the infrastructure needs to be destroyed after the experiments. For this purpose one can run the clean-up code segment from before. Here repeated for ease of use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE1akV7VaIGV"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform destroy -auto-approve"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Flower-3-Flower-on-AWS-with-Terraform.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
