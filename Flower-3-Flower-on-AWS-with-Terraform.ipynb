{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# Using Flower on AWS with Terraform\n",
        "\n",
        "Welcome to the federated learning tutorial!\n",
        "\n",
        "In this notebook, we'll build a federated learning system and deploy on AWS. At the end of this tutorial we will have a multiple AWS VMs running where one will be the server and two others will represent clients.\n",
        "\n",
        "We are going to use [Terraform](https://www.terraform.io/) to provision the infrastructure which we are going to use. If you don't know what Terraform is read this quote from their website:\n",
        "\n",
        ">Terraform is an open-source infrastructure as code software tool that provides a consistent CLI workflow to manage hundreds of cloud services. Terraform codifies cloud APIs into declarative configuration files.\n",
        "\n",
        "Putting it simply Terraform will allow you to create infrastructure in a repeatable and usually predictable way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Infrastructure\n",
        "\n",
        "Before we begin with any actual code, make sure you have access to an AWS account. You will need a AWS_ACCESS_KEY as well as the corresponding AWS_SECRET_ACCESS_KEY. Here you can find a guide how to create and get those: [How do I create an AWS access key?](https://aws.amazon.com/de/premiumsupport/knowledge-center/create-access-key)\n",
        "\n",
        "Make sure to NOT share them with anyone or leak them accidentally as others could gain full control over your account using these secrets. When you are ready you can enter your credentials into the next section which will enable tools such as Terraform to access your AWS account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: AWS_ACCESS_KEY_ID=EXAMPLE-KEY\n",
            "env: AWS_SECRET_ACCESS_KEY=EXAMPLE-SECRET\n",
            "env: AWS_DEFAULT_REGION=eu-central-1\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables with `%env` magic command specific to Jupyter\n",
        "# Outside of Jupyter you would replace `%env` with `export`\n",
        "%env AWS_ACCESS_KEY_ID=EXAMPLE-KEY\n",
        "%env AWS_SECRET_ACCESS_KEY=EXAMPLE-SECRET\n",
        "%env AWS_DEFAULT_REGION=eu-central-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First we are going to install Terraform using some statements form the official installation [guide](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/aws-get-started). This will work on Google Colab as well as on any Debian based system as we are using apt to install \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "export DEBIAN_FRONTEND=noninteractive\n",
        "sudo apt-get update && sudo apt-get install -y gnupg software-properties-common curl\n",
        "curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -\n",
        "sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\"\n",
        "sudo apt-get update && sudo apt-get install terraform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Provision EC2 instances\n",
        "\n",
        "With Terraform installed, you are ready to create the infrastructure nessecary to run a Flower server and two clients.\n",
        "\n",
        "In this tutorial, you will provision an EC2 instance on Amazon Web Services (AWS). EC2 instances are virtual machines running on AWS. They can be started using a variety of machine images. The image we are going to use will be based on Ubuntu 20.04.\n",
        "\n",
        "#### Configuration\n",
        "\n",
        "For the purpose of grouping our Terraform configuration files we are going to create a directory called infrastructure. All our configuration files will be written into that directory. Additionally we will right away create a SSH key which we are going to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create directory infrastructure and use -p so this command becomes idempotent\n",
        "mkdir -p ./infrastructure\n",
        "\n",
        "# Create ssh key to be used later to connect ot the machines\n",
        "cd infrastructure\n",
        "\n",
        "# Delete previous key so we can reexecute this block anytime without an error\n",
        "rm flower_notebook_rsa\n",
        "\n",
        "# Create keys\n",
        "ssh-keygen -b 2048 -t rsa -N '' -f ./flower_notebook_rsa\n",
        "\n",
        "# You public key. You will need this later.\n",
        "echo \"You public key:\"\n",
        "cat flower_notebook_rsa.pub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When provisioning the machines it is desireable that they are automatically configured on startup and be ready to run Flower code. Cloud-init is a standard configuration support tool available on most Linux distributions and all major cloud providers. It allows you to pass a shell script to your instance that installs or configures the machine to your specifications. In the next step a shell script is stored in the infrastructure directory which will afterwards be used to configure the machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ./infrastructure/user_data.sh\n",
        "#!/bin/bash\n",
        "set -e\n",
        "\n",
        "# Install dependencies\n",
        "sudo apt-get update\n",
        "sudo apt-get install -y \\\n",
        "    apt-transport-https \\\n",
        "    ca-certificates \\\n",
        "    curl \\\n",
        "    gnupg \\\n",
        "    lsb-release \\\n",
        "    openssh-client \\\n",
        "    python3 \\\n",
        "    python3-pip\n",
        "\n",
        "# Install Flower\n",
        "python3 -m pip install flwr==0.18.0 torch==1.11.0 torchvision==0.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to write out `main.tf` file which will contain the primary entrypoint to our Terraform configuration. We will split the configuration onto multiple files so we can keep an overview. It is not nessecary to understand the intricacies of this but for all who are interested we recommend going through the offical Terraform [\"Get Started - AWS\"](https://learn.hashicorp.com/collections/terraform/aws-get-started) tutorial for AWS. Similarly there are also tutorials for cloud providers such as Azure, GCP and others.\n",
        "\n",
        "The previously created public key needs to be inserted here into the Terraform configuration. Scroll up and copy the public key. Replace the string \"REPLACE_ME\" in line 25 before executing the next segment and writing the configuration to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ./infrastructure/main.tf\n",
        "# Configure Terraform\n",
        "terraform {\n",
        "  required_providers {\n",
        "    aws = {\n",
        "      source  = \"hashicorp/aws\"\n",
        "      version = \"~> 3.27\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  required_version = \">= 0.14.9\"\n",
        "}\n",
        "\n",
        "# Configure AWS and the default region for all AWS resources\n",
        "provider \"aws\" {\n",
        "  profile = \"default\"\n",
        "  region  = \"eu-central-1\"\n",
        "}\n",
        "\n",
        "# Login in into the virtual machines requires a public SSH key to\n",
        "# be registered on the instance. Replace MY_PUBLIC_KEY down below\n",
        "# with your public SSH key.\n",
        "resource \"aws_key_pair\" \"default\" {\n",
        "  key_name   = \"workshop\"\n",
        "  public_key = \"REPLACE_ME\"\n",
        "}\n",
        "\n",
        "# Add one instance for the Flower server. We are using a m5a instance type\n",
        "# as the m instances are not limited by CPU credits. This is quite important\n",
        "# as the machines will utilize most of their resources. The m5a has 2 vCPU\n",
        "# and 8 GiB RAM. \n",
        "resource \"aws_instance\" \"flower_server\" {\n",
        "  # Use a data reference for cross-region compatibility\n",
        "  ami           = data.aws_ami.ubuntu.id\n",
        "  instance_type = \"m5a.large\"\n",
        "  key_name      = aws_key_pair.default.key_name\n",
        "\n",
        "  root_block_device {\n",
        "    # Size of disk in GiB\n",
        "    volume_size = \"30\"\n",
        "  }\n",
        "\n",
        "  user_data     = \"${file(\"user_data.sh\")}\"\n",
        "\n",
        "  vpc_security_group_ids = [\n",
        "    aws_security_group.flower.id\n",
        "  ]\n",
        "\n",
        "  tags = {\n",
        "    Name = \"FlowerServer\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Additionally we are going to start Flower instances\n",
        "resource \"aws_instance\" \"flower_clients\" {\n",
        "  # Use a data reference for cross-region compatibility\n",
        "  ami           = data.aws_ami.ubuntu.id\n",
        "  instance_type = \"m5a.large\"\n",
        "  key_name      = aws_key_pair.default.key_name\n",
        "  count         = 2\n",
        "\n",
        "  user_data     = \"${file(\"user_data.sh\")}\"\n",
        "\n",
        "  root_block_device {\n",
        "    # Size of disk in GiB\n",
        "    volume_size = \"30\"\n",
        "  }\n",
        "\n",
        "  vpc_security_group_ids = [\n",
        "    aws_security_group.flower.id\n",
        "  ]\n",
        "\n",
        "  tags = {\n",
        "    Name = \"FlowerClient\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Define a data element to make sure we get the right AWS AMI\n",
        "# independent of the region in which we start the EC2 instance.\n",
        "# The same AMI image might have different ID's in different \n",
        "# AWS regions.\n",
        "data \"aws_ami\" \"ubuntu\" {\n",
        "  most_recent = true\n",
        "\n",
        "  filter {\n",
        "    name   = \"name\"\n",
        "    values = [\"*ubuntu-focal-20.04-amd64-server-20211129\"]\n",
        "  }\n",
        "\n",
        "  filter {\n",
        "    name   = \"virtualization-type\"\n",
        "    values = [\"hvm\"]\n",
        "  }\n",
        "  # AWS owner id of Canonical\n",
        "  # Find out with:\n",
        "  # aws ec2 describe-images \\\n",
        "  # --filters \"Name=name,Values=*ubuntu-focal-20.04-amd64-server-20211129\"\n",
        "  owners = [\"099720109477\"]\n",
        "}\n",
        "\n",
        "resource \"aws_default_vpc\" \"default\" {\n",
        "  tags = {\n",
        "    Name = \"Default VPC\"\n",
        "  }\n",
        "}\n",
        "\n",
        "resource \"aws_security_group\" \"flower\" {\n",
        "  name        = \"floewr\"\n",
        "  description = \"All ports required for a Flower server\"\n",
        "  vpc_id      = aws_default_vpc.default.id\n",
        "\n",
        "  ingress = [\n",
        "    {\n",
        "      description      = \"SSH\"\n",
        "      from_port        = 22\n",
        "      to_port          = 22\n",
        "      protocol         = \"tcp\"\n",
        "      cidr_blocks      = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "      security_groups = null\n",
        "      prefix_list_ids  = null\n",
        "      self = null\n",
        "    },\n",
        "    {\n",
        "      description      = \"HTTP\"\n",
        "      from_port        = 8080\n",
        "      to_port          = 8080\n",
        "      protocol         = \"tcp\"\n",
        "      cidr_blocks      = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "      security_groups = null\n",
        "      prefix_list_ids  = null\n",
        "      self = null\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  egress = [\n",
        "    {\n",
        "      description      = \"Any\"\n",
        "      from_port        = 0\n",
        "      to_port          = 0\n",
        "      protocol         = \"-1\"\n",
        "      cidr_blocks      = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "      security_groups = null\n",
        "      prefix_list_ids  = null\n",
        "      self = null\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  tags = {\n",
        "    Name = \"flower\"\n",
        "  }\n",
        "}\n",
        "\n",
        "output \"server_ip\" {\n",
        "  description = \"Public IP address of server\"\n",
        "  value       = aws_instance.flower_server.public_ip\n",
        "}\n",
        "\n",
        "output \"client_1_ip\" {\n",
        "  description = \"Public IP address of clients\"\n",
        "  value       = aws_instance.flower_clients[0].public_ip\n",
        "}\n",
        "\n",
        "output \"client_2_ip\" {\n",
        "  description = \"Public IP address of clients\"\n",
        "  value       = aws_instance.flower_clients[1].public_ip\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initialize Terraform\n",
        "\n",
        "Now its time to initialize Terraform in the infrastructure directory. As long as we don't have any errors in our Terraform files this should just work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Infrastructure - plan & apply Terraform\n",
        "\n",
        "Now after Terraform is successfully initialized plan and apply the Terraform configuration. By doing so Terraform is going to create infrastructure in the AWS account. As a first step running `terraform plan` will show what Terraform would do if applied. Running `terraform apply -auto-approve` will do the plan step and immidiatly apply those. In a setting where these commands are run in a native terminal one can directly run `terraform apply` as Terraform will than (without the `-auto-approve` option present) ask the user if the proposed changes should be applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "# Run this first\n",
        "terraform plan\n",
        "\n",
        "# Rerun this code segment after removing the # from the next line\n",
        "# terraform apply will do the plan step again and than apply it\n",
        "# -auto-approve is required as in Jupyter we can't confirm as we\n",
        "# have no TTY\n",
        "terraform apply -auto-approve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a note while Terraform will return its output earlier the execution of the cloud-init scripts start as soon as the machines are running. The IPs of these machines will later on be used upload or execute code on those. For that purpose making them available as ENV variables will save some time. Copy those into the next code segment so it becomes easier later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace the \"REPLACE_ME\" with the correct IP\n",
        "%env CLIENT_1_IP=REPLACE_ME\n",
        "%env CLIENT_2_IP=REPLACE_ME\n",
        "%env SERVER_IP=REPLACE_ME\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clean-up\n",
        "\n",
        "Now after the infrastructure is deployed and running it is also important to understand how to stop it. As long as its running it will incure cost which makes it quite important to remember to cleanup after our experiments are done. Ideally you should configure as much of the infrastructure in a way that its automatically cleaned up. The best way to remove infrastructure created with Terraform is to use the `terraform destroy` commmand. Terraform is stateful and the state in our case will be in `./infrastructure/.terraform`. Using the state Terraform will only destroy resource it created and not remove anything else. __Don't run this now!__ but rather come back here and run it when you stop working on this notebook and want to cleanup the infrastructure you have created. If you would like to test how it works you can naturally execute this code block now but you will have to provision the infrastructure once more by running the previous code block. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd ./infrastructure\n",
        "terraform destroy -auto-approve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Excercise\n",
        "\n",
        "Split the security group into two. One for SSH and one for the port required by the Flower server. Afterwards make sure the client instances don't expose the server port."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The experiment\n",
        "\n",
        "Three instances are now available but no Flower code is yet deployed. Application deployment can be quite complex and depending on various requirements. This tutorial will keep it quite simple so the concept is understood. Our build artifacts will a `server.py` and `client.py` file which is uploaded to the respective machine. More advanced setups might use Docker containers which are pushed to a registry and than downloaded and started on the respective machines. Alternatively tools such as ArgoCD on a Kubernetes Cluster could be used. These more advanced setups can unfortunatly not be in the scope of this tutorial.\n",
        "\n",
        "### Preparation\n",
        "\n",
        "For the preparation we are going to create a directory called app where we will store all the files which we are going to upload to \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create directory app and use -p so this command becomes idempotent\n",
        "mkdir -p ./app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Server\n",
        "\n",
        "The first thing needed is a server. The default Flower server is extremly simple and will use FedAvg by default. For this showcase we will use just that and allow the user to customize the code after we have shown that everything works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ./app/server.py\n",
        "# Flower Server\n",
        "import flwr as fl\n",
        "\n",
        "# Start Flower server\n",
        "fl.server.start_server(\n",
        "  server_address=\"0.0.0.0:8080\",\n",
        "  config={\"num_rounds\": 3},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Client\n",
        "\n",
        "Additionally the client script needs to be written and stored to disk. The client naturally needs to know the IP of the server. For this purpose scroll upwards and lookup in the Terraform output the server IP address and adjust the next code segment so that the correct IP address is inserted.\n",
        "\n",
        "_Hint: Look at the last line._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile ./app/client.py\n",
        "# Flower Client\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# #############################################################################\n",
        "# Regular PyTorch pipeline: nn.Module, train, test, and DataLoader\n",
        "# #############################################################################\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net(nn.Module):\n",
        "  \"\"\"Model (simple CNN adapted from 'PyTorch: A 60 Minute Blitz')\"\"\"\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return self.fc3(x)\n",
        "\n",
        "def train(net, trainloader, epochs):\n",
        "  \"\"\"Train the model on the training set.\"\"\"\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "  for _ in range(epochs):\n",
        "    for images, labels in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      criterion(net(images.to(DEVICE)), labels.to(DEVICE)).backward()\n",
        "      optimizer.step()\n",
        "\n",
        "def test(net, testloader):\n",
        "  \"\"\"Validate the model on the test set.\"\"\"\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  correct, total, loss = 0, 0, 0.0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "      outputs = net(images.to(DEVICE))\n",
        "      loss += criterion(outputs, labels.to(DEVICE)).item()\n",
        "      total += labels.size(0)\n",
        "      correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  return loss / len(testloader.dataset), correct / total\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"Load CIFAR-10 (training and test set).\"\"\"\n",
        "  trf = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  trainset = CIFAR10(\"./data\", train=True, download=True, transform=trf)\n",
        "  testset = CIFAR10(\"./data\", train=False, download=True, transform=trf)\n",
        "  return DataLoader(trainset, batch_size=32, shuffle=True), DataLoader(testset)\n",
        "\n",
        "# #############################################################################\n",
        "# Federating the pipeline with Flower\n",
        "# #############################################################################\n",
        "\n",
        "# Load model and data (simple CNN, CIFAR-10)\n",
        "net = Net().to(DEVICE)\n",
        "trainloader, testloader = load_data()\n",
        "\n",
        "# Define Flower client\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "  def get_parameters(self):\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "  def set_parameters(self, parameters):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "  def fit(self, parameters, config):\n",
        "    self.set_parameters(parameters)\n",
        "    train(net, trainloader, epochs=1)\n",
        "    return self.get_parameters(), len(trainloader.dataset), {}\n",
        "\n",
        "  def evaluate(self, parameters, config):\n",
        "    self.set_parameters(parameters)\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    return float(loss), len(testloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "# Start Flower client\n",
        "# REPLACE_THIS_WITH_THE_SERVER_IP\n",
        "fl.client.start_numpy_client(\"SERVER_IP_REPLACE_THIS:8080\", client=FlowerClient())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deployment\n",
        "\n",
        "After we have defined our `server.py` and `client.py` we have to upload those to the respective machines. Afterwards we are going to first start the server and following that the clients. For uploading the files we are going to use [scp](https://linux.die.net/man/1/scp) which can be find on most UNIX systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Use `set -ex` to see the actual command with $SERVER_IP resolved\n",
        "# which will be executed and stop if any of the commands fail\n",
        "set -ex\n",
        "\n",
        "function upload {\n",
        "    scp -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" $@\n",
        "}\n",
        "\n",
        "# Upload code\n",
        "upload ./app/server.py ubuntu@$SERVER_IP:/home/ubuntu/\n",
        "upload ./app/client.py ubuntu@$CLIENT_1_IP:/home/ubuntu/\n",
        "upload ./app/client.py ubuntu@$CLIENT_2_IP:/home/ubuntu/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next starting the `server.py` and `client.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Use `set -ex` to see the actual command with $SERVER_IP resolved\n",
        "# which will be executed and stop if any of the commands fail\n",
        "set -ex\n",
        "\n",
        "function run {\n",
        "    ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" $@\n",
        "}\n",
        "\n",
        "# Start server and clients\n",
        "# Note: Using screen here so that the command continues to run when the ssh connection closes.\n",
        "#       When connecting to the instance via SSH one can easily connect to the screen session\n",
        "#       by using screen -r \n",
        "\n",
        "echo ----------------- Server ------------------                && \\\n",
        "run ubuntu@$SERVER_IP \"screen -d -L -m python3 server.py\"       && \\\n",
        "sleep 5                                                         && \\\n",
        "echo ----------------- Client 1 ----------------                && \\\n",
        "run ubuntu@$CLIENT_1_IP \"screen -d -L -m python3 client.py\"     && \\\n",
        "echo ----------------- Client 2 ----------------                && \\\n",
        "run ubuntu@$CLIENT_2_IP \"screen -d -L -m python3 client.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introspection\n",
        "\n",
        "In the next step the server log will be streamed using ssh so the process can be monitored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Use `set -ex` to see the actual command with $SERVER_IP resolved\n",
        "# which will be executed and stop if any of the commands fail\n",
        "\n",
        "function run {\n",
        "    ssh -i ./infrastructure/flower_notebook_rsa -o \"StrictHostKeyChecking=no\" $@\n",
        "}\n",
        "\n",
        "# Logs\n",
        "echo ----------------- Server Log ------------------  && \\\n",
        "run ubuntu@$SERVER_IP \"cat screenlog.0\"               && \\\n",
        "echo ----------------- Client 1 Log ----------------  && \\\n",
        "run ubuntu@$CLIENT_1_IP \"cat screenlog.0\"             && \\\n",
        "echo ----------------- Client 2 Log ----------------  && \\\n",
        "run ubuntu@$CLIENT_2_IP \"cat screenlog.0\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FlowerIntroduction.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
